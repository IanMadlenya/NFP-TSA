---
title: "Project NFP - Final Report"
author: "Sam Choi, Eric Xu"
date: "4/17/2018"
geometry: margin=0.5in
output:
  pdf_document: default
  html_document:
      fig_height: 3
      fig_width: 4
      keep_md: true
  
---

\setlength{\footskip}{20pt}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DataComputing)
library(astsa)
#setwd("~/Dropbox/Berkeley/stat153/NFP-TSA/")
```

<<<<<<< HEAD

# Introduction
=======
### Introduction

The Non Farm Payroll (NFP) Report is a monthly government report tracking the number of payrolls in the U.S., excluding farm workers, private household employees, and non-profit organization employees. It is collected and reported by the the U.S. Bureau of Labor Statistics (BLS), and is an influential economic indicator used to analyze the state of the labor market. 

The release of monthly NFP Reports has significant ramifications for economic policy makers and market participants. Thus, it is imperative for both economists and traders to have a general forecast of the next month's NFP Report in order to prepare for the volatility that ensues with the release of the report. 

The monthly data is collected by the BLS as a component of the Current Employment Statistics (CES) survey. About a third of all NFP workers are surveyed, and the value reported is the result of additional extrapolation and adjustment.

The objective of this analysis is twofold: To determine the extent to which seasonal and non-seasonal trends can be captured using techniques in univariate time series analysis, and to accurately forecast future NFP Reports.


>>>>>>> c347d579cc7b6871ee48a933a27751c8f895e908

The Non Farm Payroll (NFP) Report is a monthly government report tracking the number of payrolls in the U.S., excluding farm workers, private household employees, and non-profit organization employees. It is collected and reported by the the U.S. Bureau of Labor Statistics (BLS), and is an influential economic indicator used to analyze the state of the labor market. 

The release of monthly NFP Reports has significant ramifications for economic policy makers and market participants. Thus, it is imperative for both economists and traders to have a general forecast of the next month's NFP Report in order to prepare for the volatility that ensues with the release of the report. 

The monthly data is collected by the BLS as a component of the Current Employment Statistics (CES) survey. About a third of all NFP workers are surveyed, and the value reported is the result of additional extrapolation and adjustment.

The objective of this analysis is twofold: To determine the extent to which seasonal and non-seasonal trends can be captured using techniques in univariate time series analysis, and to accurately forecast future NFP Reports.


# Data Analysis

## Exploratory Data Analysis

We aim to explore PAYNSA, PAYEMS a dataset of non farm payrolls without seasonal adjustments. The data is recorded in thousands of persons, and contains monthly NFP report values from January 1939 to March 2018.  

#### Not Seasonally Adjusted (PAYNSA)
```{r}
```

#### Narrowing Our Scope
Throughout the 80 years represented in these datasets, various events have occurred that significantly changed the conditions of the economy. For this reason, we will limit our analysis to the years that followed the financial crisis of 2007/2008. By narrowing our scope to 2010-2018, we aim to provide a more telling analysis of the trends associated with the post-recession economic recovery.

#### Not Seasonally Adjusted (PAYNSA) 2010-2018
```{r}
```

### Change in Payrolls
First order differencing of SA and NSA data

#### NSA Differences 2010-2018
```{r}
```
Taking the first difference seems to have detrended the original time series, and plotting the histogram indicates that the change in total payrolls may follow a left-skewed distribution, characterized by the long left tail above. 

Next we mean-center the SA_diff time series:  
```{r}
```

*make note on stationarity


## ARIMA Model Building

We will use the Box-Jenkins method to build an ARIMA model for the non-seasonally adjusted (NSA) NFP data. We begin by transforming the data set to achieve stationarity.

### Transforming the dataset to achieve stationarity

We begin by transforming the data set to achieve stationarity. We do so by first using a lagged difference with a period of 12 months, producing a time series that resembles a random walk. We then apply differencing again to achieve stationarity.

```{r fig.height = 3, echo=FALSE}
PAYNSA <- read.csv(file = "PAYNSA.csv", header = TRUE, sep = ",")
nfp_nsa_ts <- ts(PAYNSA[853:951,][2])

par(mfrow=c(1,2))

NSA_sdiff <- diff(nfp_nsa_ts, lag = 12, differences = 1)
NSA_smean <- mean(NSA_sdiff)
centered_NSA_sdiff <- NSA_sdiff - NSA_smean
plot.ts(centered_NSA_sdiff, main = "Centered NSA Seasonal Diffs", xlab = "Months (since January 2010)", ylab = "Number of Payrolls")

NSA_sdiff2 <- diff(NSA_sdiff, lag = 1, differences = 1)
plot.ts(NSA_sdiff2, main = "After Differencing Again")
```

Figure #. NSA data after lagged difference (left) and after lagged difference plus differencing again (right)

This now resembles white noise with fairly consistent variance, with slightly higher variance in the first 20 months of the data.

### Model selection

We now inspect the ACF and PACF plots of the transformed time series.

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
acf(NSA_sdiff2, main = "ACF")
pacf(NSA_sdiff2, main = "PACF")
```

Figure #. ACF and PACF plots of the transformed time series


Neither the ACF nor PACF appear to be significant at any lag. This further supports the notion that our transformed time series is very close to white noise, or an ARMA(0, 0) model. Therefore, fitting any non-zero order ARMA model and proceeding with parameter estimation will likely produce a model with poor predictive properties including bias. Therefore, instead of fitting an ARMA model we turn to spectral analysis to analyze the seasonal variation of our time series from a frequency perspective.


## Spectral Analysis

Analyzing the time series using spectral analysis allows us to identify the key frequencies of variation in the non-seasonally adjusted NFP time series. 

We begin by transforming the dataset into a stationary time series. We will compare the estimated spectral densities for two methods of transformation: differencing and curve-fitting. We will refer to the time series transformed by curve-fitting as the detrended time series.

### Nonparametric Spectral Estimation

We begin by generating raw periodograms for both the differenced and detrended time series. 

```{r fig.height = 3, echo=FALSE}
PAYNSA <- read.csv(file = "PAYNSA.csv", header = TRUE, sep = ",")
nfp_nsa_ts_2010_2018 <- ts(PAYNSA[853:951, ][2])

differenced_NSA <- diff(nfp_nsa_ts_2010_2018)

par(mfrow=c(1,2))
mvspec(differenced_NSA, detrend = FALSE)
mvspec(nfp_nsa_ts_2010_2018)
```

Figure #. Differenced and detrended raw periodograms

As expected, both periodograms are bumpy with similar peaks, but the differenced time series produces a raw periodogram with a much lower baseline in the 0.0 to 0.1 frequency range and the detrended time series produces a raw periodogram with a lower baseline in the 0.26 to 0.28 frequency range. This means in the differenced time series, the peak at a frequency of about 0.08 is more significant, and in the detrended time series, the peaks at 0.25 and 0.33 are more significant. 

To reduce the variance of the periodogram and better identify significant peaks, we will apply smoothing to the periodogram using various parameters to find a better estimate of the spectral density. We begin with a daniell kernel with m = 1.

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
mvspec(differenced_NSA, kernel("daniell", 1), log = "no")
mvspec(nfp_nsa_ts_2010_2018, kernel("daniell", 1), log = "no")
```

Figure #. Smoothed periodograms of differenced and detrended time series using a Daniell kernel (m = 1)

This looks quite smooth already. Using m = 2 results in wider peaks shown in the Appendix, possibly introducing bias. Therefore, setting m = 1 is an adequate amount of smoothing that allows us to identify significant peaks while minimizing bias.

To further reduce bias and narrow the peaks, we can apply smoothing with the modified Daniell kernel with m = 1.

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
mvspec(differenced_NSA, kernel("modified.daniell", 1), log = "no")
mvspec(nfp_nsa_ts_2010_2018, kernel("modified.daniell", 1), log = "no")
```

Figure #. Smoothed periodograms of differenced and detrended time series using a modified Daniell kernel (m = 1)

Smoothing using the modified Daniell kernel produces much sharper peaks. There does not appear to be much bumpiness remaining so tapering should not be necessary. To see the smoothed and tapered periodogram, see Appendix.

The tapering does not change the estimated spectral density significantly and the same frequency peaks remain. This suggests our data set has very clean and predictable cyclical variation, and we can now find the frequencies of the most significant peaks. We do so by finding the local maxima (Method from Stack Overflow).

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))

pgram_diffed <- mvspec(differenced_NSA, kernel("modified.daniell", 1), log = "no")
key_freq_ind <- c(1, which(diff(sign(diff(pgram_diffed$spec)))==-2) + 1)
key_freq <- pgram_diffed$freq[key_freq_ind]
abline(v=key_freq, lty=2)

pgram_detrend <- mvspec(nfp_nsa_ts_2010_2018, kernel("modified.daniell", 1), log = "no")
key_freq_ind <- c(1, which(diff(sign(diff(pgram_detrend$spec)))==-2) + 1)
key_freq <- pgram_detrend$freq[key_freq_ind]
abline(v=key_freq, lty=2)
```

Figure #. Smoothed and tapered periodograms overlaid with local maxima.

In the differenced time series, we can identify three major peaks: one at a frequency of about 0.17, corresponding to a semiannual cycle, one at a frequency of about 0.5, corresponding to a two-month cycle, and one at a frequency of about 0.33, corresponding to a quarterly cycle.

The smoothed periodogram of the detrended data has two major peaks: one at a frequency of about 0.08, corresponding to an annual cycle, the largest at a frequency of about 0.17, corresponding to a semiannual cycle, and one at a frequency of 0.08, corresponding to an annual cycle. Two other, less significant peaks appear, one at 0.01 and one at 0.5.

### Parametric Spectral Estimation

We can now compare our smoothed and tapered periodograms with the estimated spectral density generating using parametric spectral estimation.

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
mvspec(nfp_nsa_ts_2010_2018, kernel("modified.daniell", 1), log = "no")
pgram_ar <- spec.ar(differenced_NSA, plot=F)
lines(pgram_ar$freq, pgram_ar$spec, lty=2, col="red")

mvspec(differenced_NSA, kernel("modified.daniell", 1), log = "no")
pgram_ar <- spec.ar(differenced_NSA, plot=F)
lines(pgram_ar$freq, pgram_ar$spec, lty=2, col="red")
```

Figure #. Smoothed and tapered periodograms overlaid with parametric spectral estimator. 

The parametric spectral estimator has peaks at frequencies 0.08, 0.17, 0.25, 0.33, 0.42, and 0.50. This matches the frequencies of peaks seen in the differenced and detrended time series. However, the size of the peaks at these frequencies differs between the two time series.

The peaks at 0.08, 0.17 match the detrended time series periodogram in frequency and size, with much less significant peaks at the other frequencies. The differenced time series has its three major peaks at 0.17, 0.33, and 0.50, with much less significant peaks at the other frequencies. 



## Forecasting





# Conclusion

## Key Takeaways

Jobs are added and lost according to a highly consistent seasonal pattern. TODO

Linear job growth since the Great Recession ended. TODO

## Interesting Findings

Cycles of variation every quarter, 6 months, year align with the seasons. TODO

Seasonal and first differencing removes cyclical and trend variation, leaving us with essentially white noise. TODO

Different key frequencies highlighted by differencing vs detrending. TODO

## Future Analysis

Analyzing other time periods. TODO


\newpage

# Appendix

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
mvspec(differenced_NSA, kernel("daniell", 2), log = "no")
mvspec(nfp_nsa_ts_2010_2018, kernel("daniell", 2), log = "no")
```

Figure #. Smoothed periodograms of differenced and detrended time series using a Daniell kernel (m = 2)

```{r fig.height = 3, echo=FALSE}
par(mfrow=c(1,2))
mvspec(nfp_nsa_ts_2010_2018, kernel("modified.daniell", 1), log = "no", taper = 0.2)
mvspec(differenced_NSA, kernel("modified.daniell", 1), log = "no", taper = 0.2)
```

Figure #. Smoothed and tapered periodograms of differenced and detrended time series using a modified Daniell kernel (m = 1)



